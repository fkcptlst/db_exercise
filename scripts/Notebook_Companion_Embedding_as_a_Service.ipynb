{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPg2HdoH8o2p"
   },
   "source": [
    "# Getting Started With Embeddings: Notebook Companion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0N6a-RPS9jLg"
   },
   "source": [
    "![](/../assets/80_getting_started_with_embeddings/thumbnail.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70e0sP4t-Cvx"
   },
   "source": [
    "## 1. Embedding a dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "d_McQCASzpT_"
   },
   "outputs": [],
   "source": [
    "model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "hf_token = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23fNFAm1h24M"
   },
   "source": [
    "The first time you generate the embeddings it may take a while (approximately 20 seconds) for the API to return them. We use the `retry` decorator (install with `pip install retry`) so that if on the first try `output = query(dict(inputs = texts))` doesn't work, wait 10 seconds and try again three times. The reason this happens is because on the first request, the model needs to be downloaded and installed in the server, but subsequent calls are much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uvEXtWmsgK2B"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Kg0HaYGSz2GC"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from retry import retry\n",
    "\n",
    "api_url = f\"https://api-inference.huggingface.co/pipeline/feature-extraction/{model_id}\"\n",
    "headers = {\"Authorization\": f\"Bearer {hf_token}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DStL7NC_h1J0"
   },
   "outputs": [],
   "source": [
    "@retry(tries=3, delay=10)\n",
    "def query(texts):\n",
    "    response = requests.post(api_url, headers=headers, json={\"inputs\": texts})\n",
    "    result = response.json()\n",
    "    if isinstance(result, list):\n",
    "      return result\n",
    "    elif list(result.keys())[0] == \"error\":\n",
    "      print(result)\n",
    "      raise RuntimeError(\n",
    "          \"The model is currently loading, please re-run the query.\"\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "u7iHNzsq05k7"
   },
   "outputs": [],
   "source": [
    "texts = [\"How do I get a replacement Medicare card?\",\n",
    "        \"What is the monthly premium for Medicare Part B?\",\n",
    "        \"How do I terminate my Medicare Part B (medical insurance)?\",\n",
    "        \"How do I sign up for Medicare?\",\n",
    "        \"Can I sign up for Medicare Part B if I am working and have health insurance through an employer?\",\n",
    "        \"How do I sign up for Medicare Part B if I already have Part A?\",\n",
    "        \"What are Medicare late enrollment penalties?\",\n",
    "        \"What is Medicare and who can get it?\",\n",
    "        \"How can I get help with my Medicare Part A and Part B premiums?\",\n",
    "        \"What are the different parts of Medicare?\",\n",
    "        \"Will my Medicare premiums be higher because of my higher income?\",\n",
    "        \"What is TRICARE ?\",\n",
    "        \"Should I sign up for Medicare Part B if I have Veterans’ Benefits?\"]\n",
    "\n",
    "output = query(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PVDIE076NIZB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "embeddings = pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ElAxRHyzjrd4",
    "outputId": "649a09a4-9724-4df3-d030-98f796f5c161"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         0         1         2         3         4         5         6    \\\n0  -0.023889  0.055259 -0.011655 -0.033414 -0.012261 -0.024873 -0.012663   \n1  -0.012688  0.046874 -0.010502 -0.020384 -0.013361  0.042322  0.016628   \n2   0.000494  0.119412  0.005229 -0.092734  0.007773 -0.005325  0.034506   \n3  -0.029711  0.023298 -0.057041 -0.012183 -0.013710  0.029796  0.063739   \n4  -0.025628  0.070389 -0.017380 -0.056567  0.028577  0.052823  0.067063   \n5  -0.022656  0.021160  0.005105 -0.046494  0.009074  0.041495  0.054268   \n6  -0.002911  0.060791 -0.009176 -0.006133  0.040492  0.036594  0.002054   \n7  -0.080526  0.059888 -0.048847 -0.040176 -0.063342  0.041848  0.119045   \n8  -0.034388  0.072501  0.014440 -0.036695  0.014019  0.063070  0.034683   \n9  -0.005964  0.025044 -0.003182 -0.025243 -0.039823 -0.012772  0.044713   \n10 -0.039008 -0.010609 -0.007383 -0.050190 -0.002518 -0.041641  0.026969   \n11 -0.095983 -0.063012 -0.116906 -0.059075 -0.051323 -0.003439  0.018687   \n12 -0.011629  0.059619  0.016509 -0.094747 -0.008346  0.070966  0.042429   \n\n         7         8         9    ...       374       375       376       377  \\\n0   0.025346  0.018508 -0.083508  ... -0.161688 -0.046426  0.006004  0.005281   \n1  -0.004099 -0.002607 -0.010188  ... -0.061594 -0.020717 -0.009082 -0.029260   \n2  -0.051981 -0.006265 -0.006111  ... -0.108326 -0.049646 -0.073399 -0.029898   \n3   0.001101 -0.045124 -0.040748  ... -0.117682  0.031924  0.000854  0.020200   \n4  -0.052618 -0.054702 -0.116230  ... -0.118145  0.013343 -0.055188 -0.032723   \n5  -0.024185 -0.013483 -0.075966  ... -0.100110  0.010750 -0.031469 -0.004822   \n6  -0.031345  0.031806 -0.023495  ... -0.028763 -0.060458 -0.018598 -0.040189   \n7   0.010652 -0.030095 -0.004561  ... -0.144566  0.020404  0.023088  0.005077   \n8  -0.014531 -0.059862 -0.045383  ... -0.114763 -0.035894 -0.019877 -0.033375   \n9   0.014535 -0.038213 -0.041149  ... -0.057621  0.021594  0.048983 -0.044541   \n10 -0.014801 -0.014127 -0.061637  ... -0.098168 -0.031694 -0.052128  0.014774   \n11  0.006544 -0.049057 -0.031649  ... -0.041085 -0.008593 -0.021544 -0.021112   \n12 -0.041212 -0.038502 -0.099356  ... -0.135191  0.011535 -0.050499 -0.007376   \n\n         378       379       380       381       382       383  \n0  -0.003342  0.027754  0.020411  0.005778  0.034098 -0.006889  \n1  -0.066253  0.065257  0.013229 -0.023103 -0.002785  0.010474  \n2  -0.102734  0.062121  0.034606  0.016877 -0.023861  0.005264  \n3  -0.020666 -0.005167  0.038370  0.003617  0.033993 -0.010255  \n4   0.008436  0.019169  0.048212 -0.040412  0.083346  0.026855  \n5   0.039657  0.026384  0.045514  0.059089 -0.017509  0.007166  \n6  -0.031486 -0.018299  0.002286 -0.073420  0.016235 -0.000244  \n7  -0.055645 -0.007675  0.050791 -0.005989  0.134562  0.034817  \n8  -0.030168  0.039412  0.044993  0.000578 -0.025124  0.034191  \n9  -0.030137  0.006779  0.054854  0.029937  0.070214  0.041565  \n10 -0.091150  0.001324  0.053866 -0.083904  0.037684  0.002314  \n11 -0.019502  0.050040 -0.029175  0.005498  0.152892  0.024720  \n12  0.084258 -0.008294  0.034186 -0.028212 -0.001166  0.001067  \n\n[13 rows x 384 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>374</th>\n      <th>375</th>\n      <th>376</th>\n      <th>377</th>\n      <th>378</th>\n      <th>379</th>\n      <th>380</th>\n      <th>381</th>\n      <th>382</th>\n      <th>383</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.023889</td>\n      <td>0.055259</td>\n      <td>-0.011655</td>\n      <td>-0.033414</td>\n      <td>-0.012261</td>\n      <td>-0.024873</td>\n      <td>-0.012663</td>\n      <td>0.025346</td>\n      <td>0.018508</td>\n      <td>-0.083508</td>\n      <td>...</td>\n      <td>-0.161688</td>\n      <td>-0.046426</td>\n      <td>0.006004</td>\n      <td>0.005281</td>\n      <td>-0.003342</td>\n      <td>0.027754</td>\n      <td>0.020411</td>\n      <td>0.005778</td>\n      <td>0.034098</td>\n      <td>-0.006889</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.012688</td>\n      <td>0.046874</td>\n      <td>-0.010502</td>\n      <td>-0.020384</td>\n      <td>-0.013361</td>\n      <td>0.042322</td>\n      <td>0.016628</td>\n      <td>-0.004099</td>\n      <td>-0.002607</td>\n      <td>-0.010188</td>\n      <td>...</td>\n      <td>-0.061594</td>\n      <td>-0.020717</td>\n      <td>-0.009082</td>\n      <td>-0.029260</td>\n      <td>-0.066253</td>\n      <td>0.065257</td>\n      <td>0.013229</td>\n      <td>-0.023103</td>\n      <td>-0.002785</td>\n      <td>0.010474</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000494</td>\n      <td>0.119412</td>\n      <td>0.005229</td>\n      <td>-0.092734</td>\n      <td>0.007773</td>\n      <td>-0.005325</td>\n      <td>0.034506</td>\n      <td>-0.051981</td>\n      <td>-0.006265</td>\n      <td>-0.006111</td>\n      <td>...</td>\n      <td>-0.108326</td>\n      <td>-0.049646</td>\n      <td>-0.073399</td>\n      <td>-0.029898</td>\n      <td>-0.102734</td>\n      <td>0.062121</td>\n      <td>0.034606</td>\n      <td>0.016877</td>\n      <td>-0.023861</td>\n      <td>0.005264</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.029711</td>\n      <td>0.023298</td>\n      <td>-0.057041</td>\n      <td>-0.012183</td>\n      <td>-0.013710</td>\n      <td>0.029796</td>\n      <td>0.063739</td>\n      <td>0.001101</td>\n      <td>-0.045124</td>\n      <td>-0.040748</td>\n      <td>...</td>\n      <td>-0.117682</td>\n      <td>0.031924</td>\n      <td>0.000854</td>\n      <td>0.020200</td>\n      <td>-0.020666</td>\n      <td>-0.005167</td>\n      <td>0.038370</td>\n      <td>0.003617</td>\n      <td>0.033993</td>\n      <td>-0.010255</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.025628</td>\n      <td>0.070389</td>\n      <td>-0.017380</td>\n      <td>-0.056567</td>\n      <td>0.028577</td>\n      <td>0.052823</td>\n      <td>0.067063</td>\n      <td>-0.052618</td>\n      <td>-0.054702</td>\n      <td>-0.116230</td>\n      <td>...</td>\n      <td>-0.118145</td>\n      <td>0.013343</td>\n      <td>-0.055188</td>\n      <td>-0.032723</td>\n      <td>0.008436</td>\n      <td>0.019169</td>\n      <td>0.048212</td>\n      <td>-0.040412</td>\n      <td>0.083346</td>\n      <td>0.026855</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>-0.022656</td>\n      <td>0.021160</td>\n      <td>0.005105</td>\n      <td>-0.046494</td>\n      <td>0.009074</td>\n      <td>0.041495</td>\n      <td>0.054268</td>\n      <td>-0.024185</td>\n      <td>-0.013483</td>\n      <td>-0.075966</td>\n      <td>...</td>\n      <td>-0.100110</td>\n      <td>0.010750</td>\n      <td>-0.031469</td>\n      <td>-0.004822</td>\n      <td>0.039657</td>\n      <td>0.026384</td>\n      <td>0.045514</td>\n      <td>0.059089</td>\n      <td>-0.017509</td>\n      <td>0.007166</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>-0.002911</td>\n      <td>0.060791</td>\n      <td>-0.009176</td>\n      <td>-0.006133</td>\n      <td>0.040492</td>\n      <td>0.036594</td>\n      <td>0.002054</td>\n      <td>-0.031345</td>\n      <td>0.031806</td>\n      <td>-0.023495</td>\n      <td>...</td>\n      <td>-0.028763</td>\n      <td>-0.060458</td>\n      <td>-0.018598</td>\n      <td>-0.040189</td>\n      <td>-0.031486</td>\n      <td>-0.018299</td>\n      <td>0.002286</td>\n      <td>-0.073420</td>\n      <td>0.016235</td>\n      <td>-0.000244</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>-0.080526</td>\n      <td>0.059888</td>\n      <td>-0.048847</td>\n      <td>-0.040176</td>\n      <td>-0.063342</td>\n      <td>0.041848</td>\n      <td>0.119045</td>\n      <td>0.010652</td>\n      <td>-0.030095</td>\n      <td>-0.004561</td>\n      <td>...</td>\n      <td>-0.144566</td>\n      <td>0.020404</td>\n      <td>0.023088</td>\n      <td>0.005077</td>\n      <td>-0.055645</td>\n      <td>-0.007675</td>\n      <td>0.050791</td>\n      <td>-0.005989</td>\n      <td>0.134562</td>\n      <td>0.034817</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>-0.034388</td>\n      <td>0.072501</td>\n      <td>0.014440</td>\n      <td>-0.036695</td>\n      <td>0.014019</td>\n      <td>0.063070</td>\n      <td>0.034683</td>\n      <td>-0.014531</td>\n      <td>-0.059862</td>\n      <td>-0.045383</td>\n      <td>...</td>\n      <td>-0.114763</td>\n      <td>-0.035894</td>\n      <td>-0.019877</td>\n      <td>-0.033375</td>\n      <td>-0.030168</td>\n      <td>0.039412</td>\n      <td>0.044993</td>\n      <td>0.000578</td>\n      <td>-0.025124</td>\n      <td>0.034191</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>-0.005964</td>\n      <td>0.025044</td>\n      <td>-0.003182</td>\n      <td>-0.025243</td>\n      <td>-0.039823</td>\n      <td>-0.012772</td>\n      <td>0.044713</td>\n      <td>0.014535</td>\n      <td>-0.038213</td>\n      <td>-0.041149</td>\n      <td>...</td>\n      <td>-0.057621</td>\n      <td>0.021594</td>\n      <td>0.048983</td>\n      <td>-0.044541</td>\n      <td>-0.030137</td>\n      <td>0.006779</td>\n      <td>0.054854</td>\n      <td>0.029937</td>\n      <td>0.070214</td>\n      <td>0.041565</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>-0.039008</td>\n      <td>-0.010609</td>\n      <td>-0.007383</td>\n      <td>-0.050190</td>\n      <td>-0.002518</td>\n      <td>-0.041641</td>\n      <td>0.026969</td>\n      <td>-0.014801</td>\n      <td>-0.014127</td>\n      <td>-0.061637</td>\n      <td>...</td>\n      <td>-0.098168</td>\n      <td>-0.031694</td>\n      <td>-0.052128</td>\n      <td>0.014774</td>\n      <td>-0.091150</td>\n      <td>0.001324</td>\n      <td>0.053866</td>\n      <td>-0.083904</td>\n      <td>0.037684</td>\n      <td>0.002314</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>-0.095983</td>\n      <td>-0.063012</td>\n      <td>-0.116906</td>\n      <td>-0.059075</td>\n      <td>-0.051323</td>\n      <td>-0.003439</td>\n      <td>0.018687</td>\n      <td>0.006544</td>\n      <td>-0.049057</td>\n      <td>-0.031649</td>\n      <td>...</td>\n      <td>-0.041085</td>\n      <td>-0.008593</td>\n      <td>-0.021544</td>\n      <td>-0.021112</td>\n      <td>-0.019502</td>\n      <td>0.050040</td>\n      <td>-0.029175</td>\n      <td>0.005498</td>\n      <td>0.152892</td>\n      <td>0.024720</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>-0.011629</td>\n      <td>0.059619</td>\n      <td>0.016509</td>\n      <td>-0.094747</td>\n      <td>-0.008346</td>\n      <td>0.070966</td>\n      <td>0.042429</td>\n      <td>-0.041212</td>\n      <td>-0.038502</td>\n      <td>-0.099356</td>\n      <td>...</td>\n      <td>-0.135191</td>\n      <td>0.011535</td>\n      <td>-0.050499</td>\n      <td>-0.007376</td>\n      <td>0.084258</td>\n      <td>-0.008294</td>\n      <td>0.034186</td>\n      <td>-0.028212</td>\n      <td>-0.001166</td>\n      <td>0.001067</td>\n    </tr>\n  </tbody>\n</table>\n<p>13 rows × 384 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKJJzhYX-OEA"
   },
   "source": [
    "## 2. Host embeddings for free on the Hugging Face Hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "UGQ0g9DM2wn_"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install huggingface-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pk9el6S52qZl",
    "outputId": "41e548c3-9ef5-4001-e262-da3ef944fb46"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    To login, `huggingface_hub` now requires a token generated from https://huggingface.co/settings/tokens .\n",
      "    \n",
      "Token: "
     ]
    }
   ],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z06NVe-83wf1"
   },
   "outputs": [],
   "source": [
    "!huggingface-cli repo create embedded_faqs_medicare --type dataset --organization ITESM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "beO4nEln40-N"
   },
   "outputs": [],
   "source": [
    "# This is code required to install git-lfs however it already is installed in Colab instances.\n",
    "#!git lfs install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2O0b5awa4uTd"
   },
   "outputs": [],
   "source": [
    "!git clone https://{your HF user here}:{your token here}@huggingface.co/datasets/ITESM/embedded_faqs_medicare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pSVebbDq6n4g"
   },
   "outputs": [],
   "source": [
    "embeddings.to_csv(\"embedded_faqs_medicare/embeddings.csv\", index=False)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iezsa2P38rie"
   },
   "source": [
    "Changing directory to our repo `embedded_faqs_medicare`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VU2t0vL18gJw"
   },
   "outputs": [],
   "source": [
    "%cd embedded_faqs_medicare/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZFTmNB_7BJu"
   },
   "outputs": [],
   "source": [
    "!git lfs track *.csv\n",
    "!git add .gitattributes\n",
    "!git add embeddings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-kDcX1lb9xWP"
   },
   "outputs": [],
   "source": [
    "!git config --global user.email \"your email here\"\n",
    "!git config --global user.name \"your git user here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GMsNtanX8yOj"
   },
   "outputs": [],
   "source": [
    "!git commit -m \"First version of the embedded_faqs_medicare dataset\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azsWjRb9-gZY"
   },
   "source": [
    "## 3. Get the most similar Frequently Asked Questions to a query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "miTP1yro5Xnq"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c_kc0dbl5H9d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "faqs_embeddings = load_dataset('ITESM/embedded_faqs_medicare')\n",
    "dataset_embeddings = torch.from_numpy(faqs_embeddings[\"train\"].to_pandas().to_numpy()).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tb5yJd7ABUBG"
   },
   "outputs": [],
   "source": [
    "question = [\"How can Medicare help me?\"]\n",
    "output = query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t3TBXYhi3sof"
   },
   "outputs": [],
   "source": [
    "query_embeddings = torch.FloatTensor(output)\n",
    "print(f\"The size of our embedded dataset is {dataset_embeddings.shape} and of our embedded query is {query_embeddings.shape}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gwVWBV8i4ldh"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NHlOjB-17zKk"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'query_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_21584\\412480661.py\u001B[0m in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msentence_transformers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutil\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msemantic_search\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mhits\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msemantic_search\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mquery_embeddings\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdataset_embeddings\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtop_k\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'query_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.util import semantic_search\n",
    "\n",
    "hits = semantic_search(query_embeddings, dataset_embeddings, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3P2poeGiecM6"
   },
   "outputs": [],
   "source": [
    "[texts[hits[0][i]['corpus_id']] for i in range(len(hits[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "ShmlACLrRmcZ"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Notebook Companion: Embedding-as-a-Service.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
